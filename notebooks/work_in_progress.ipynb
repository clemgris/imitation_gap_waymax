{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-03 16:02:40.584207: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-11-03 16:02:41.544510: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-11-03 16:02:41.544623: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-11-03 16:02:41.544637: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import dataclasses\n",
    "import jax\n",
    "from jax import random\n",
    "from jax import numpy as jnp\n",
    "import mediapy\n",
    "\n",
    "from waymax import agents\n",
    "from waymax import config as _config\n",
    "from waymax import dynamics\n",
    "from waymax import dataloader\n",
    "from waymax import datatypes\n",
    "from waymax import env as _env\n",
    "from waymax.datatypes import observation\n",
    "from waymax.datatypes import object_state\n",
    "from waymax.dynamics import discretizer\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('./')\n",
    "\n",
    "from utils import plot_observation_with_mask\n",
    "\n",
    "CURRENT_TIME_INDEX = 10\n",
    "N_SIMULATION_STEPS = 80\n",
    "N_ROLLOUTS = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "WOD_1_1_0_TRAINING = _config.DatasetConfig(\n",
    "    path='/data/saruman/cleain/WOD_1_1_0/tf_example/training/training_tfexample.tfrecord@1000',\n",
    "    max_num_rg_points=20000,\n",
    "    data_format=_config.DataFormat.TFRECORD,\n",
    "    batch_dims = (4,),\n",
    "    max_num_objects=8\n",
    ")\n",
    "\n",
    "WOD_1_1_0_VALIDATION = _config.DatasetConfig(\n",
    "    path='/data/saruman/cleain/WOD_1_1_0/tf_example/validation/validation_tfexample.tfrecord@150',\n",
    "    max_num_rg_points=20000,\n",
    "    data_format=_config.DataFormat.TFRECORD,\n",
    "    max_num_objects=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-03 16:02:43.920318: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-11-03 16:02:43.920427: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-11-03 16:02:43.920497: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-11-03 16:02:43.920566: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-11-03 16:02:43.972706: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-11-03 16:02:43.972993: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "CUDA backend failed to initialize: Found cuSOLVER version 11405, but JAX was built against version 11502, which is newer. The copy of cuSOLVER that is installed must be at least as new as the version against which JAX was built. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/cleain/.local/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    }
   ],
   "source": [
    "data_iter = dataloader.simulator_state_generator(config=WOD_1_1_0_TRAINING)\n",
    "\n",
    "scenario = next(data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for scenario in data_iter:\n",
    "    if i > 10:\n",
    "        break\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = []\n",
    "traj_len = 80\n",
    "\n",
    "# Env\n",
    "\n",
    "env_config = _config.EnvironmentConfig(\n",
    "    # Ensure that the sim agent can control all valid objects.\n",
    "    controlled_object=_config.ObjectType.VALID,\n",
    "    max_num_objects=8\n",
    ")\n",
    "\n",
    "dynamics_model = dynamics.InvertibleBicycleModel()\n",
    "discrete_dynamic_model = discretizer.DiscreteActionSpaceWrapper(dynamics_model=dynamics_model,\n",
    "                                                                bins=128 * jnp.ones_like(dynamics_model.action_spec(), dtype='uint8'))\n",
    "\n",
    "env = _env.MultiAgentEnvironment(\n",
    "    dynamics_model=discrete_dynamic_model,\n",
    "    config=env_config,\n",
    ")\n",
    "\n",
    "expert_agent = agents.create_expert_actor(discrete_dynamic_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedArray(shape=(2,), dtype=dtype('float32'), name=None, minimum=[-6.  -0.3], maximum=[6.  0.3])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dynamics_model.action_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16641], dtype=int32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discrete_dynamic_model.action_spec().maximum+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 8, 1)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert_agent.select_action(None, scenario, None, None).action.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_agent.select_action(None, scenario, None, None).action.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the observayion datatype and updating the simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_len = 80\n",
    "roadgraph_top_k = 1000\n",
    "\n",
    "jit_sdc_obs_from_state = jax.jit(datatypes.sdc_observation_from_state)\n",
    "\n",
    "obs = []\n",
    "\n",
    "current_state = env.reset(scenario)\n",
    "for _ in range(traj_len):\n",
    "    current_state = datatypes.update_state_by_log(current_state, num_steps=1)\n",
    "\n",
    "    # sdc_obs = jit_sdc_obs_from_state(current_state, roadgraph_top_k=roadgraph_top_k)\n",
    "    sdc_obs = datatypes.sdc_observation_from_state(current_state, roadgraph_top_k=roadgraph_top_k)\n",
    "    \n",
    "    obs.append(sdc_obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the initial simulator state and log trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_len = 80\n",
    "\n",
    "current_state = env.reset(scenario)\n",
    "\n",
    "# Identify SDC agent\n",
    "sdc_idx = jax.lax.top_k(current_state.object_metadata.is_sdc, k=1)[1]\n",
    "sdc_x = jnp.take_along_axis(current_state.log_trajectory.x, sdc_idx[..., jnp.newaxis], axis=-2)\n",
    "sdc_y = jnp.take_along_axis(current_state.log_trajectory.y, sdc_idx[..., jnp.newaxis], axis=-2)\n",
    "\n",
    "sdc_xy = jnp.take_along_axis(current_state.log_trajectory.xy, sdc_idx[..., jnp.newaxis, jnp.newaxis], axis=-3)\n",
    "\n",
    "sdc_yaw = jnp.take_along_axis(current_state.log_trajectory.yaw, sdc_idx[..., jnp.newaxis], axis=-2)\n",
    "sdc_valid = jnp.take_along_axis(current_state.log_trajectory.valid, sdc_idx[..., jnp.newaxis], axis=-2)\n",
    "\n",
    "\n",
    "# # Translate the object positions\n",
    "# obj_x = current_state.log_trajectory.x\n",
    "# obj_y = current_state.log_trajectory.y\n",
    "\n",
    "# sdc_x = jnp.tile(sdc_x, (1, obj_x.shape[1], 1))\n",
    "# sdc_y = jnp.tile(sdc_y, (1, obj_y.shape[1], 1))\n",
    "\n",
    "# obj_x = obj_x - sdc_x\n",
    "# obj_y = obj_y - sdc_y\n",
    "\n",
    "# obs = {'obj_x': obj_x,\n",
    "#        'obj_y': obj_y,\n",
    "#        }\n",
    "\n",
    "# # Translate roadmap ## To be continued\n",
    "\n",
    "\n",
    "# Translate the light signals\n",
    "\n",
    "global_obs = observation.global_observation_from_state(current_state, obs_num_steps=1, num_obj=1)\n",
    "sdc_pose2D = jnp.take_along_axis(global_obs.pose2d, sdc_idx[..., jnp.newaxis], axis=-1)\n",
    "\n",
    "pose2d = observation.ObjectPose2D.from_center_and_yaw(xy=sdc_xy, yaw=sdc_yaw, valid=sdc_valid) #Problem\n",
    "\n",
    "pose = observation.combine_two_object_pose_2d(src_pose=sdc_pose2D, dst_pose=pose2d)\n",
    "\n",
    "transf_traj = observation.transform_trajectory(current_state.log_trajectory, pose)\n",
    "transf_rg = observation.transform_roadgraph_points(current_state.roadgraph_static_points, pose)\n",
    "transf_tls = observation.transform_traffic_lights(current_state.traffic_lights, pose)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 20000)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_state.roadgraph_points.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test rnnBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'roadgraph_top_k': 100,\n",
    "    'NUM_ENVS': 4,\n",
    "    'NUM_STEPS': 80,\n",
    "    'KEY': random.PRNGKey(42)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "\n",
    "class Transition(NamedTuple):\n",
    "    done: jnp.ndarray\n",
    "    expert_action: jnp.array\n",
    "    obs: jnp.ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/data/saruman/cleain/imitation_gap_womd/notebooks/work_in_progress.ipynb Cell 18\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6a6f6c6c795f77696c6c69616d73222c2273657474696e6773223a7b22686f7374223a227373683a2f2f736172756d616e227d7d/data/saruman/cleain/imitation_gap_womd/notebooks/work_in_progress.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m current_state \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mreset(scenario)\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6a6f6c6c795f77696c6c69616d73222c2273657474696e6773223a7b22686f7374223a227373683a2f2f736172756d616e227d7d/data/saruman/cleain/imitation_gap_womd/notebooks/work_in_progress.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m obsv \u001b[39m=\u001b[39m datatypes\u001b[39m.\u001b[39msdc_observation_from_state(current_state,\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6a6f6c6c795f77696c6c69616d73222c2273657474696e6773223a7b22686f7374223a227373683a2f2f736172756d616e227d7d/data/saruman/cleain/imitation_gap_womd/notebooks/work_in_progress.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m                                     roadgraph_top_k\u001b[39m=\u001b[39mconfig[\u001b[39m'\u001b[39m\u001b[39mroadgraph_top_k\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6a6f6c6c795f77696c6c69616d73222c2273657474696e6773223a7b22686f7374223a227373683a2f2f736172756d616e227d7d/data/saruman/cleain/imitation_gap_womd/notebooks/work_in_progress.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m expert_action \u001b[39m=\u001b[39m expert_agent\u001b[39m.\u001b[39mselect_action(state\u001b[39m=\u001b[39mcurrent_state, params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, rng\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, actor_state\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'env' is not defined"
     ]
    }
   ],
   "source": [
    "current_state = env.reset(scenario)\n",
    "obsv = datatypes.sdc_observation_from_state(current_state,\n",
    "                                    roadgraph_top_k=config['roadgraph_top_k'])\n",
    "\n",
    "expert_action = expert_agent.select_action(state=current_state, params=None, rng=None, actor_state=None)\n",
    "\n",
    "runner_state = (current_state,\n",
    "                expert_action,\n",
    "                obsv,\n",
    "                jnp.zeros((config[\"NUM_ENVS\"]), dtype=bool),\n",
    "                )\n",
    "\n",
    "# COLLECT TRAJECTORIES FROM scenario\n",
    "def _env_step(runner_state, unused):\n",
    "    current_state, expert_action, _, _ = runner_state\n",
    "    \n",
    "    current_state = datatypes.update_state_by_log(current_state, num_steps=1)\n",
    "    done = jnp.tile(current_state.is_done, (4,))\n",
    "\n",
    "    obsv = datatypes.sdc_observation_from_state(current_state,\n",
    "                                                roadgraph_top_k=config['roadgraph_top_k'])\n",
    "\n",
    "    expert_action = expert_agent.select_action(state=current_state, params=None, rng=None, actor_state=None)\n",
    "    \n",
    "    # Add a mask here\n",
    "\n",
    "    runner_state = (current_state, expert_action, obsv, done)\n",
    "\n",
    "    transition = Transition(done,\n",
    "                            expert_action,\n",
    "                            obsv\n",
    "                            )\n",
    "    return runner_state, transition\n",
    "\n",
    "# Use jax.lax.scan with the modified _env_step function\n",
    "_, traj_batch = jax.lax.scan(f=_env_step, init=runner_state, xs=None, length=config[\"NUM_STEPS\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 4, 1, 8, 1, 2)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traj_batch.obs.trajectory.xy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_x = jnp.zeros((1, 4, 8, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_x_reshaped = init_x.reshape((1, 4, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4, 16)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_x_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Env config\n",
    "env_config = _config.EnvironmentConfig(\n",
    "    # Ensure that the sim agent can control all valid objects.\n",
    "    controlled_object=_config.ObjectType.SDC,\n",
    "    max_num_objects=8\n",
    ")\n",
    "\n",
    "dynamics_model = dynamics.InvertibleBicycleModel()\n",
    "\n",
    "action_space_dim = dynamics_model.action_spec().shape\n",
    "dynamics_model = dynamics.discretizer.DiscreteActionSpaceWrapper(dynamics_model=dynamics_model,\n",
    "                                                                 bins=128 * jnp.ones((action_space_dim), dtype='uint8'))\n",
    "\n",
    "dynamics_model = _env.PlanningAgentDynamics(dynamics_model)\n",
    "\n",
    "env = _env.PlanningAgentEnvironment(dynamics_model=dynamics_model,\n",
    "                                    config=env_config,\n",
    "                                    )\n",
    "\n",
    "# DEFINE EXPERT AGENT\n",
    "expert_agent = agents.create_expert_actor(dynamics_model)\n",
    "\n",
    "# INIT ENV\n",
    "current_state = env.reset(scenario)\n",
    "obsv = datatypes.sdc_observation_from_state(current_state,\n",
    "                                            roadgraph_top_k=100)\n",
    "\n",
    "expert_action = expert_agent.select_action(state=current_state,\n",
    "                                            actor_state=None,\n",
    "                                            params=None,\n",
    "                                            rng=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert_action.action.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
